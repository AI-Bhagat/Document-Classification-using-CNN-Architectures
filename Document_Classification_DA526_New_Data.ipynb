{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e774ef",
   "metadata": {
    "id": "d3e774ef",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### DA 526 - Image Processing with Machine Learning\n",
    "## Document Classification\n",
    "\n",
    "### Instructor - Dr. Debanga Raj Neog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22eb7c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Author_1 - Atul Bhagat\n",
    "#### Roll Number - 224156004\n",
    "#### Email - b.atul@iitg.ac.in\n",
    "#### Date - 7th March 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8c341",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We'll start with importing all the required libraries for this project.\n",
    "\n",
    "We are using python-v8 on MacOS.\n",
    "\n",
    "Required Libraries -\n",
    "    Tensorflow\n",
    "    Numpy\n",
    "    Matplotlib\n",
    "    Pandas\n",
    "\n",
    "Note: It is important to install these libraries beforehand in your local environment. Creating a virtual environment is also highly recommended as it won't mess with the existing python (Global) libraries. Check the compatible tensorflow version and accordingly compatible numpy library must be installed. This information is available on their website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, ZeroPadding2D\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow_Version_\", tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The first segment of the code initializes the necessary libraries and modules required for the project. It imports the following libraries and modules:\n",
    "\n",
    "os: This library provides functions for interacting with the operating system, such as accessing file directories and performing system-related operations.\n",
    "\n",
    "tensorflow (tf): TensorFlow is an open-source machine learning framework that offers a comprehensive set of tools and resources for building and deploying machine learning models.\n",
    "\n",
    "matplotlib.pyplot: Matplotlib is a popular plotting library used for creating visualizations, including graphs and charts.\n",
    "\n",
    "tensorflow.keras.models.Sequential: This module allows the construction of sequential models in TensorFlow, which are comprised of a linear stack of layers.\n",
    "\n",
    "tensorflow.keras.layers: This module provides various types of layers used in neural network architectures, such as Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, and ZeroPadding2D.\n",
    "\n",
    "tensorflow.keras: The keras module within TensorFlow offers a high-level API for designing and training neural networks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import splitfolders\n",
    "#\n",
    "# input_folder = 'Data_Large/train'\n",
    "# output_folder = 'Split'\n",
    "#\n",
    "# splitfolders.ratio(input=input_folder, output=output_folder,\n",
    "#                    seed=1337, ratio=(.7, .15, .15), group_prefix=None, move=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "7d0dc7ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Printing few basic environment details!\n",
    "\n",
    "This code involves configuring GPU settings and printing system information. It performs the following tasks:\n",
    "\n",
    "Checks if GPUs are available and sets memory growth to avoid memory errors.\n",
    "\n",
    "Prints the environment variables for further analysis.\n",
    "\n",
    "Prints the number of available GPUs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to True to avoid memory errors\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "for k, v in os.environ.items():\n",
    "    print(f'{k} = {v}')\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# labels = pd.read_csv(\"train_labels.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This code defines various configuration settings for the project. These settings include:\n",
    "\n",
    "Image Size: The desired size (in pixels) for the input images. In this case, the variable i_s is set to 224.\n",
    "\n",
    "Batch Size: The number of samples per gradient update during training. The variable batch_size is set to 32.\n",
    "\n",
    "Epochs: The number of times the entire dataset will be passed through the model during training. The variable epochs is set to 30.\n",
    "\n",
    "Patience: The number of epochs to wait before early stopping if no improvement in the validation metric is observed. The variable patience is set to 6.\n",
    "\n",
    "Learning Rate: The rate at which the model's weights are updated during training. The variable learning_rate is set to 0.0001.\n",
    "\n",
    "Optimizer: The optimization algorithm used for updating the model's weights. In this case, the variable opt is set to use the Adam optimizer with the specified learning rate.\n",
    "\n",
    "Metrics: The evaluation metrics used to assess the model's performance. The variable metric is a list that includes accuracy, precision, and recall.\n",
    "\n",
    "Loss Function: The loss function used to measure the model's performance during training. The variable loss is set to use categorical cross-entropy.\n",
    "\n",
    "Data Augmentation: Various image augmentation techniques to enhance the diversity of the training data. These techniques include rotation, width and height shifts, shearing, zooming, horizontal flipping, and fill mode for pixel interpolation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Image Size\n",
    "i_s = 256\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "patience = 6\n",
    "learning_rate = 0.001\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "metric = ['accuracy']\n",
    "loss = tf.losses.categorical_crossentropy\n",
    "\n",
    "rotation_range = 10\n",
    "width_shift_range = 0.4\n",
    "height_shift_range = 0.4\n",
    "shear_range = 0.3\n",
    "zoom_range = 0.4\n",
    "horizontal_flip = True\n",
    "fill_mode = \"nearest\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This snippet defines a function called extract_hidden_layer_data. This function is responsible for extracting and visualizing the activations of the hidden layers in a given model. Here's an overview of what the code does:\n",
    "\n",
    "The function takes three parameters: path (the path to the saved model), sample (a sample image for visualization), and nc (the number of columns for the subplot grid).\n",
    "\n",
    "The saved model is loaded using tf.keras.models.load_model.\n",
    "\n",
    "A folder named \"plots\" is created if it doesn't exist, to save the generated plots.\n",
    "\n",
    "For each convolutional layer (Conv2D) in the model, the code performs the following steps:\n",
    "\n",
    "1. Prints the name of the current layer.\n",
    "2. Sets up an activation model to obtain the layer outputs given the input image.\n",
    "3. Predicts the activations for the sample image using the activation model.\n",
    "4. Plots the activations for each filter in a grid.\n",
    "5. Saves the plot as an image in the \"plots\" folder, organized by the model name and the layer name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30a9a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_hidden_layer_data(path, sample, nc):\n",
    "    model = tf.keras.models.load_model(path)\n",
    "    import os\n",
    "    from matplotlib import pyplot as plt\n",
    "    # Create a folder for saving the plots if it doesn't exist\n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots')\n",
    "\n",
    "    # Getting a sample image\n",
    "    x_test = sample\n",
    "    # plt.imshow(x_test, cmap='Greys')\n",
    "    # plt.title(\"Sample Image\")\n",
    "\n",
    "    for l_name in model.layers:\n",
    "        if isinstance(l_name, tf.keras.layers.Conv2D):\n",
    "            print(\"Layer -\", l_name.name)\n",
    "            layer_name = l_name.name\n",
    "            layer_outputs = [layer.output for layer in model.layers if layer.name == layer_name]\n",
    "            activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "            activations = activation_model.predict(x_test)\n",
    "\n",
    "            # Plot the output\n",
    "\n",
    "            # The i*4+j index is used to access the i-th row and j-th column of the array,\n",
    "            # and then the imshow() method of the corresponding subplot is called to display the image.\n",
    "            num_col = nc\n",
    "            fig, ax = plt.subplots(nrows=l_name.filters // num_col, ncols=num_col, figsize=(60,60))\n",
    "            for i in range(l_name.filters // num_col):\n",
    "                for j in range(num_col):\n",
    "                    ax[i, j].imshow(activations[0, :, :, i * num_col + j], cmap='gray')\n",
    "                    ax[i, j].axis('off')\n",
    "\n",
    "            # m_name = path.split(\"Saved_Models/\")[1].split(\"_\")[0]\n",
    "            # print()\n",
    "            # print(\"Current working directory:\", os.getcwd())\n",
    "            # export = f'plots/{m_name}/{l_name.name}'\n",
    "            # print(\"Expected path:\", export)\n",
    "            # print()\n",
    "            #\n",
    "            # if not os.path.exists(export):\n",
    "            #     os.makedirs(export)\n",
    "            #\n",
    "            # plt.savefig(f'{export}/{l_name.name}.png', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7deb37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_image(i_s):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "    sample_image = datagen.flow_from_directory('./Data/testlabeled/', target_size=(i_s, i_s),\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               class_mode='categorical',\n",
    "                                               subset='training',\n",
    "                                               batch_size=1,shuffle='True')\n",
    "\n",
    "    return sample_image.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df2a3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_samples(data):\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "\n",
    "    img, label = data.next()\n",
    "    print(\"BatchSize, TargetSize_H, TargetSize_W, Channels\", img.shape)  #  (16,256,256,1)\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = GridSpec(3, 3, figure=fig)\n",
    "\n",
    "    fig.suptitle(\" == Sample Images == \")\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "    ax1.imshow(img[0], cmap=\"gray\")\n",
    "    ax2.imshow(img[1], cmap=\"gray\")\n",
    "    ax3.imshow(img[2], cmap=\"gray\")\n",
    "    ax4.imshow(img[3], cmap=\"gray\")\n",
    "    ax5.imshow(img[4], cmap=\"gray\")\n",
    "    ax6.imshow(img[5], cmap=\"gray\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Augmentation\n",
    "\n",
    "The fifth snippet of the code defines a function called get_data that handles the loading and augmentation of the dataset. Here's a breakdown of what the code does:\n",
    "\n",
    "The function takes several parameters, including i_s (image size), batch_size, and various augmentation parameters such as rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip, fill_mode, and color.\n",
    "\n",
    "Two instances of tf.keras.preprocessing.image.ImageDataGenerator are created: train_datagen and test_datagen. The train_datagen is used for data augmentation during training, while test_datagen is used for rescaling without augmentation during validation and testing.\n",
    "\n",
    "The training data is loaded using train_datagen.flow_from_directory, which reads the images from the specified directory and applies the specified data augmentation techniques.\n",
    "\n",
    "The validation and testing data are loaded using test_datagen.flow_from_directory. Unlike the training data, the validation and testing data are not augmented.\n",
    "\n",
    "The function returns three iterators: train (for training data), val (for validation data), and test (for testing data)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7838b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(i_s, batch_size, rotation_range=0, width_shift_range=0, height_shift_range=0, shear_range=0, zoom_range=0,\n",
    "             horizontal_flip=False, fill_mode=\"nearest\", color=\"grayscale\"):\n",
    "    # Here we are using inbuilt ImageDataGenerator from tensorflow package.\n",
    "    # This caters to two of our needs - 1). This provides in-pipe data augmentation, that is, every image fed through this datagen would have some random augmentation done to it, to reduce over-fitting and this helps in generalising better.\n",
    "    # 2) This works by creating a memory buffer, where we give it the path to our images, inside that path all the folder names would be considered as labels and each folder would contain images corresponding to that particular class.\n",
    "    # Note : We've organised the data before-hand in this manner, so that we could use the flow_from_directory function directly.\n",
    "\n",
    "\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255.,\n",
    "                                                                    rotation_range=rotation_range,\n",
    "                                                                    width_shift_range=width_shift_range,\n",
    "                                                                    height_shift_range=height_shift_range,\n",
    "                                                                    shear_range=shear_range,\n",
    "                                                                    zoom_range=zoom_range,\n",
    "                                                                    horizontal_flip=horizontal_flip,\n",
    "                                                                    fill_mode=fill_mode\n",
    "                                                                    )\n",
    "\n",
    "    # Note that the validation data should not be augmented!\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "\n",
    "    # Since we have 16 classes in our dataset, we are labelling them 0-15 accordingly.\n",
    "#     clas = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15']\n",
    "\n",
    "    # A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels.\n",
    "    train = train_datagen.flow_from_directory('./Data_Large/train', batch_size=batch_size, target_size=(i_s, i_s),\n",
    "                                              color_mode=color,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "\n",
    "    val = test_datagen.flow_from_directory('./Data_Large/val', target_size=(i_s, i_s),\n",
    "                                           color_mode=color,\n",
    "                                           class_mode='categorical'\n",
    "                                           )\n",
    "\n",
    "    test = test_datagen.flow_from_directory('./Data_Large/test', target_size=(i_s, i_s),\n",
    "                                            color_mode=color,\n",
    "                                            class_mode='categorical',\n",
    "                                            shuffle=False)\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a710bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def start_training(model, model_name, epochs, train, val, factor=0.2, patience_reducelr=3, patience=5, min_lr=0.00001, training_samples='NoDataGiven'):\n",
    "    import os\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "    monitor = \"val_loss\"\n",
    "    enable_logging = 1\n",
    "\n",
    "    log_dir = f\"logs/fit/{model_name}___{training_samples}___samples\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    model_name_prefix = model_name.split(\"/\")[0]\n",
    "    model_filepath = f\"Saved_Models/{model_name_prefix}/{model_name_prefix}_trained_on_{training_samples}_Data.h5\"\n",
    "\n",
    "    print(f\"Model would be saved at {model_filepath}\")\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=monitor,\n",
    "                                  factor=factor,\n",
    "                                  patience=patience_reducelr,\n",
    "                                  min_lr=min_lr,\n",
    "                                  cooldown = 1,\n",
    "                                  verbose = enable_logging)\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor = monitor,\n",
    "                                                  patience=patience,\n",
    "                                                  start_from_epoch=3,\n",
    "                                                  verbose = enable_logging\n",
    "                                                 )\n",
    "    tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                        histogram_freq=1,\n",
    "                                        write_images=True\n",
    "                                        )\n",
    "\n",
    "    model_cp = ModelCheckpoint(filepath=model_filepath,\n",
    "                               monitor=monitor,\n",
    "                               save_best_only=True,\n",
    "                               verbose=enable_logging)\n",
    "\n",
    "    cb = [tb, reduce_lr, early_stop, model_cp]\n",
    "\n",
    "    trained_model = model.fit(train,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=val,\n",
    "                              callbacks=cb,\n",
    "                              verbose=enable_logging)\n",
    "    print('**10')\n",
    "    print(\"Model Training Ended\")\n",
    "    print(f\"Saved Model at {model_filepath}\")\n",
    "    print('**10')\n",
    "    print(\"(HISTORY) Parameters used for Model Fitting \")\n",
    "    print(trained_model.params)\n",
    "\n",
    "    return trained_model, model_filepath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training\n",
    "\n",
    "The sixth snippet of the code defines a function called start_training that handles the training process for a given model. Here's a breakdown of what the code does:\n",
    "\n",
    "The function takes several parameters, including the model to be trained, model_name, epochs, train data iterator, val data iterator, and various training-related parameters such as factor, patience_reducelr, patience, min_lr, and training_samples.\n",
    "\n",
    "Several callbacks are set up for monitoring and saving the best model during training. These include ReduceLROnPlateau (to reduce learning rate on plateau), EarlyStopping (to stop training early if no improvement is observed), TensorBoard (to log training progress), and ModelCheckpoint (to save the best model during training).\n",
    "\n",
    "The function creates a log directory to store the training logs and a directory to save the trained model.\n",
    "\n",
    "The model is trained using the fit function, which takes the training and validation data iterators, the number of epochs, and the defined callbacks.\n",
    "\n",
    "After training, the function prints information about the saved model and the parameters used for model fitting.\n",
    "\n",
    "The function returns the trained model and the file path where the model is saved."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def retrain_model(model_path, new_learning_rate, epochs, train, val, patience=3):\n",
    "    try:\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "    except:\n",
    "        print(\"Unable to load the model\")\n",
    "\n",
    "    learning_rate = new_learning_rate\n",
    "    previous_opt = loaded_model.optimizer\n",
    "    previous_opt.learning_rate.assign(learning_rate)\n",
    "\n",
    "    # mn = loaded_model.__name__\n",
    "    model_name = f'Retrained_'\n",
    "    trained_model, model_filepath = start_training(loaded_model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))\n",
    "\n",
    "    # Add best save callback\n",
    "    save_callback = tf.keras.callbacks.ModelCheckpoint(filepath='Retrained_Model_{model_name}.h5',\n",
    "                                                       monitor='val_loss',\n",
    "                                                       save_best_only=True)\n",
    "    trained_model.fit(train,\n",
    "                      validation_data=val,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=[save_callback])\n",
    "\n",
    "    return trained_model, model_filepath\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retraining the Model\n",
    "\n",
    "This code snippet defines a function called retrain_model that allows retraining a pre-trained model with a new learning rate. Here's a breakdown of what the code does:\n",
    "\n",
    "The function takes several parameters, including the model_path (path to the pre-trained model), new_learning_rate, epochs, train data iterator, val data iterator, and patience.\n",
    "\n",
    "The pre-trained model is loaded using tf.keras.models.load_model function and stored in the loaded_model variable.\n",
    "\n",
    "The learning rate of the optimizer in the loaded model is updated with the new learning rate.\n",
    "\n",
    "The function generates a new model name for the retrained model and calls the start_training function with the loaded model, new model name, and other parameters for training.\n",
    "\n",
    "The start_training function is responsible for training the model with the provided data and parameters.\n",
    "\n",
    "Finally, the function returns the trained model and the file path where the model is saved."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83393c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_saved_model(model_filepath, test):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "    predictions = model.predict(test)\n",
    "\n",
    "    y_true = test.labels\n",
    "    y_pred_labels = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_mat = tf.math.confusion_matrix(y_true, y_pred_labels)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "    return conf_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix and Classification Report\n",
    "\n",
    "The eighth code snippet defines a function called confusion_matrix that calculates and visualizes the confusion matrix and classification report for a given model and test dataset. Here's a breakdown of what the code does:\n",
    "\n",
    "The function takes the model_filepath (path to the trained model file) and test data iterator as input.\n",
    "\n",
    "The trained model is loaded using tf.keras.models.load_model function.\n",
    "\n",
    "Predictions are obtained using the loaded model on the test dataset.\n",
    "\n",
    "The true labels (y_true) are extracted from the test dataset.\n",
    "\n",
    "The function iterates through the predictions and compares them with the true labels to identify misclassifications. It collects misclassification information in the error_list and calculates the accuracy.\n",
    "\n",
    "The function calculates the F1-score using sklearn.metrics.f1_score and prints it.\n",
    "\n",
    "The confusion matrix is computed using sklearn.metrics.confusion_matrix and printed.\n",
    "\n",
    "The classification report is generated using sklearn.metrics.classification_report and printed.\n",
    "\n",
    "If the number of classes is less than or equal to 16, a heatmap of the confusion matrix is plotted using seaborn.heatmap and saved as a JPEG file.\n",
    "\n",
    "Finally, the confusion matrix and classification report are returned."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc966b72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " def confusion_matrix(model_filepath, test):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "    predictions = model.predict(test)\n",
    "\n",
    "    y_true = test.labels\n",
    "    # y_pred_labels = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    classes = list(test.class_indices.keys())\n",
    "    # print(classes)\n",
    "    count_classes = len(classes)\n",
    "    no_of_samples = len(predictions)\n",
    "\n",
    "    error_list = []\n",
    "    y_pred = []\n",
    "    errors = 0\n",
    "\n",
    "    for i, pred in enumerate(predictions):\n",
    "        file = test.filenames[i]\n",
    "        pred_label = np.argmax(pred)\n",
    "        true_label = test.labels[i]\n",
    "        # print(\"Prediction\", pred_label, \"TrueLabel\", true_label)\n",
    "        if pred_label != true_label:\n",
    "            # print(\"Misclassification has Occured\")\n",
    "            errors = errors + 1\n",
    "            filename = test.filenames[i]\n",
    "            error_class = classes[pred_label]\n",
    "            error_data = (filename, error_class)\n",
    "            error_list.append((error_data))\n",
    "        y_pred.append(pred_label)\n",
    "\n",
    "    accuracy = (1 - (errors / no_of_samples))*100\n",
    "    msg = f'Total error count : {errors}, in {no_of_samples} tests for an accuracy of {accuracy:6.2f}'\n",
    "    print(msg)\n",
    "\n",
    "    ytrue = np.array(y_true)\n",
    "    ypred = np.array(y_pred)\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    f1score = f1_score(ytrue, ypred, average='weighted') * 100\n",
    "    print(\"F1 - Score :\", f1score)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix = confusion_matrix(ytrue, ypred)\n",
    "    print(\"Confusion Matrix \\n\", confusion_matrix, \"\\n\")\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    import seaborn as sns\n",
    "    classification_report = classification_report(y_true, y_pred, target_names=classes, digits=4)\n",
    "    print(\"Classification Report \\n\", classification_report)\n",
    "\n",
    "    import datetime\n",
    "\n",
    "    date = datetime.datetime.now().strftime(\"%d-%m\")\n",
    "    time = datetime.datetime.now().strftime(\"%H.%M\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    if count_classes <= 16:\n",
    "        cm = confusion_matrix\n",
    "        # plot the confusion matrix\n",
    "        plt.figure(figsize=(8,8))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='crest', cbar=False)\n",
    "        plt.xticks(np.arange(count_classes) + 1, classes, rotation=90)\n",
    "        plt.yticks(np.arange(count_classes) + 1, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "\n",
    "        import os\n",
    "        dir = os.listdir(\"./\")\n",
    "        if \"ConfusionMatrix\" not in dir:\n",
    "            os.mkdir(\"ConfusionMatrix\")\n",
    "        else:\n",
    "            print(\"ConfusionMatrix - Directory Already Exists\")\n",
    "\n",
    "        try:\n",
    "            part = model.name.split(\"_\")[0] + '_' + date + '_' + time\n",
    "            path = f'./ConfusionMatrix/{part}'+'.jpeg'\n",
    "            plt.savefig(path, bbox_inches='tight')\n",
    "        except:\n",
    "            print('***********')\n",
    "            print('Error!!!')\n",
    "            print('***********')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### sample_image is obtained by calling the get_sample_image function with i_s as an argument. The function returns a sample image, and [0] is used to access the first image from the returned batch of images.\n",
    "\n",
    "plt.imshow is used to display the sample image.\n",
    "\n",
    "plt.show() displays the image.\n",
    "\n",
    "plt.close() is called to close the current figure and free up memory.\n",
    "\n",
    "Finally, print(i_s) is used to print the value of i_s, which represents the image size."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6a860",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_image = get_sample_image(i_s)[0]\n",
    "plt.imshow(sample_image[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(i_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f7819",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Basic CNN Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1176f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c1176f5",
    "outputId": "d8fe564b-0c2e-4f4f-f7a3-8e47c5ccc0dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train, val, test = get_data(i_s, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range,\n",
    "                            zoom_range, horizontal_flip, fill_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c8133",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_samples(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The provided code creates a convolutional neural network (CNN) model using TensorFlow and Keras. It defines the architecture of the model and compiles it with the specified loss function, optimizer, and metrics. Finally, it displays a summary of the model and a visual representation using the visualkeras library."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a1a21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "model_pfx = 'BasicCNN'\n",
    "\n",
    "date = datetime.datetime.now().strftime('%d.%m.%Y')\n",
    "time = datetime.datetime.now().strftime(\"%H..%M\")\n",
    "model_name = model_pfx + \"_inputSize_\" + str(i_s) + \"_\" + str(date) + \"_\" + str(time)\n",
    "\n",
    "with tf.name_scope(model_name):\n",
    "    model = Sequential(name=model_name)\n",
    "\n",
    "with tf.name_scope(\"conv1\"):\n",
    "    model.add(Conv2D(16, (5,5), 1,\n",
    "                     activation=\"relu\",\n",
    "                     input_shape=(i_s, i_s, 1)))\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=3))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "with tf.name_scope(\"conv2\"):\n",
    "    model.add(Conv2D(32, (3,3), 1,\n",
    "                     activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=3))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "with tf.name_scope(\"conv3\"):\n",
    "    model.add(Conv2D(64, (3, 3), 1,\n",
    "                     activation=\"relu\"))\n",
    "    # model.add(tf.keras.layers.MaxPool2D(pool_size=3))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "with tf.name_scope(\"conv4\"):\n",
    "    model.add(Conv2D(128, (3, 3), 1,\n",
    "                     activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=3))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "with tf.name_scope(\"conv5\"):\n",
    "    model.add(Conv2D(256, (3, 3), 1,\n",
    "                     activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "with tf.name_scope(\"flatten\"):\n",
    "    model.add(Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "with tf.name_scope(\"dense\"):\n",
    "    # Adding Fully Connected Layers to the model\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "with tf.name_scope(\"compile\"):\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=metric)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True, scale_xy=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbed99a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basic_CNN, model_filepath = start_training(model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c72ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cm_basicCNN, cr_basicCNN = confusion_matrix(model_filepath, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37608bc6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b37d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_filepath='Saved_Models/BasicCNN_inputSize_256_15.05.2023_20..56/BasicCNN_inputSize_256_15.05.2023_20..56_trained_on_87479_Data.h5'\n",
    "extract_hidden_layer_data(model_filepath, sample_image, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848e867",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del train, test, val, model_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9a21b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Alexnet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59fdb8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = \"AlexNet\"\n",
    "import datetime\n",
    "date = datetime.datetime.now().strftime('%d.%m.%Y')\n",
    "time = datetime.datetime.now().strftime(\"%H..%M\")\n",
    "model_name = model + \"_inputSize_\" + str(i_s) + \"_\" + str(date) + \"_\" + str(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003a90b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train, val, test = get_data(i_s, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range,\n",
    "                            zoom_range, horizontal_flip, fill_mode)\n",
    "\n",
    "print_samples(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08607448",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "model = Sequential(name=model_name)\n",
    "\n",
    "model.add(Conv2D(96, (11, 11), strides=4, input_shape=(i_s, i_s, 1)))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ZeroPadding2D(padding=2))\n",
    "model.add(Conv2D(512, (5, 5), strides=1))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# model.add(ZeroPadding2D(padding=1))\n",
    "# model.add(Conv2D(512, (3, 3), strides=1))\n",
    "# model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation=\"softmax\"))\n",
    "\n",
    "learning_rate = 0.001\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metric)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc510d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AlexNet_Model, model_filepath = start_training(model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_filepath = 'Saved_Models/AlexNet_inputSize_256_16.05.2023_15..51/AlexNet_inputSize_256_16.05.2023_15..51_trained_on_87479_Data.h5'\n",
    "AlexNet_Model, model_filepath = retrain_model(model_filepath, 0.0001, 30, train, val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96112b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cm_alexnet, cr_alexnet = confusion_matrix(model_filepath, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e1d84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extract_hidden_layer_data(model_filepath, sample_image, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65e9da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "       del train, val, test, model_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HeLUqa1vvnuy",
   "metadata": {
    "id": "HeLUqa1vvnuy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### VGG-19 Architecture Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rCgteiIbvmK1",
   "metadata": {
    "id": "rCgteiIbvmK1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# epochs = 30\n",
    "# batch_size = 32\n",
    "# i_s = 256 #Image_Size\n",
    "# patience = 5\n",
    "\n",
    "model = \"VGG-19\"\n",
    "date = datetime.datetime.now().strftime('%d.%m.%Y')\n",
    "time = datetime.datetime.now().strftime(\"%H..%M\")\n",
    "model_name = model + \"_inputSize_\" + str(i_s) + \"_\" + str(date) + \"_\" + str(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a3690",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train, val, test = get_data(i_s, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range,\n",
    "                            zoom_range, horizontal_flip, fill_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f6860",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_samples(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2f83d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential(name=model_name)\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 input_shape=(i_s, i_s, 1)))\n",
    "model.add(Conv2D(64, (3, 3), 1,\n",
    "                 activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), 1,\n",
    "                 activation=\"relu\"))\n",
    "model.add(Conv2D(128, (3, 3), 1,\n",
    "                 activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "model.add(Conv2D(512, (3, 3), 1,\n",
    "                 activation=\"relu\",\n",
    "                 padding=\"same\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metric)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True, scale_xy=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbfcdf6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "VGG_19_Model, model_filepath = start_training(model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('Saved_Models/VGG-19_inputSize_256_09.05.2023_01..14/VGG-19_inputSize_256_09.05.2023_01..14_trained_on_87479_Data.h5')\n",
    "learning_rate = 0.0001\n",
    "previous_opt = loaded_model.optimizer\n",
    "previous_opt.learning_rate.assign(learning_rate)\n",
    "VGG_19_Model, model_filepath = start_training(loaded_model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_filepath='Saved_Models/VGG-19_inputSize_256_10.05.2023_11..24/VGG-19_inputSize_256_10.05.2023_11..24_trained_on_87479_Data.h5'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63222f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cm_vgg_19, cr_vgg_19 = confusion_matrix(model_filepath, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a4d75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extract_hidden_layer_data(model_filepath, sample_image, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f296d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del train, val, test, model_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "VGG-16 Pretrained Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "# epochs = 30\n",
    "# batch_size = 32\n",
    "# i_s = 256 #Image_Size\n",
    "# patience = 5\n",
    "\n",
    "model = \"VGG-16_Pretrained\"\n",
    "date = datetime.datetime.now().strftime('%d.%m.%Y')\n",
    "time = datetime.datetime.now().strftime(\"%H..%M\")\n",
    "model_name = model + \"_inputSize_\" + str(i_s) + \"_\" + str(date) + \"_\" + str(time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, val, test = get_data(i_s, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range,\n",
    "                            zoom_range, horizontal_flip, fill_mode, \"rgb\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train.next()\n",
    "print_samples(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(i_s, i_s, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add our own layers on top of the pre-trained model\n",
    "model = Sequential(name=model_name)\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=monitor)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True, scale_xy=0.6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VGG16_Pretrained_Model, model_filepath = start_training(model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm_vgg_16, cr_vgg_16 = confusion_matrix(model_filepath, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extract_hidden_layer_data(model_filepath, sample_image, 32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del train, val, test, model_filepath"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "66CTdsJtw971",
   "metadata": {
    "id": "66CTdsJtw971",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ResNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aUANcFOJ0y_O",
   "metadata": {
    "id": "aUANcFOJ0y_O",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# epochs = 30\n",
    "# batch_size = 32\n",
    "# i_s = 256 #Image_Size\n",
    "# patience = 5\n",
    "model = \"ResNet\"\n",
    "\n",
    "date = datetime.datetime.now().strftime('%d.%m.%Y')\n",
    "time = datetime.datetime.now().strftime(\"%H..%M\")\n",
    "model_name = f'{model}_i_s_{i_s}_{date}_{time}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044de92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train, val, test = get_data(i_s, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range,\n",
    "                            zoom_range, horizontal_flip, fill_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456cbb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_samples(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5e40e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(x, filters):\n",
    "    x_input = x\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Add()([x, x_input])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def convolutional_block(x, filters):\n",
    "    x_input = x\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same', strides=(2, 2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_input = tf.keras.layers.Conv2D(filters, (1, 1), strides=(2, 2))(x_input)\n",
    "    x = tf.keras.layers.Add()([x, x_input])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet34(shape=(i_s, i_s, 1), classes=16):\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    x = tf.keras.layers.Conv2D(16, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # block_layers = [3, 4, 6, 3]\n",
    "    block_layers = [2,4,6,2]\n",
    "\n",
    "    filter_size = 16\n",
    "\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            filter_size = filter_size * 2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "\n",
    "    x = tf.keras.layers.AveragePooling2D((2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=x_input, outputs=x, name=model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vdSa_pof3HMz",
   "metadata": {
    "id": "vdSa_pof3HMz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ResNet34()\n",
    "\n",
    "learning_rate = 0.01\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss,\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True, scale_xy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de93e0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Resnet_Model, model_filepath = start_training(model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7426a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    ",cm_resnet, cr_resnet = confusion_matrix(model_filepath, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378ff46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extract_hidden_layer_data('Saved_Models/Pretrained_ResNet_50_i_s_24_12.05.2023_08..30/Pretrained_ResNet_50_i_s_24_12.05.2023_08..30_trained_on_87479_Data.h5', sample_image, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9c7c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del train, test, val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec6ebd9",
   "metadata": {
    "id": "0ec6ebd9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CHAT GPT RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# epochs = 30\n",
    "# batch_size = 32\n",
    "# i_s = 256 #Image_Size\n",
    "# patience = 5\n",
    "model = \"Pretrained_ResNet_50\"\n",
    "\n",
    "date = datetime.datetime.now().strftime('%d.%m.%Y')\n",
    "time = datetime.datetime.now().strftime(\"%H..%M\")\n",
    "model_name = f'{model}_i_s_{i_s}_{date}_{time}'\n",
    "i_s = 224"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, val, test = get_data(i_s, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range,\n",
    "                            zoom_range, horizontal_flip, fill_mode, color='rgb')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Set the number of classes in the RVL-CDIP dataset\n",
    "num_classes = 16\n",
    "\n",
    "# Load the ResNet-50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# base_model.summary()\n",
    "# Add a global average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Add the final classification layer\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True)\n",
    "# Train the model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "pretrained_Resnet_50_model, model_filepath = start_training(model, model_name, epochs, train, val, patience=patience, training_samples=str(train.samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extract_hidden_layer_data('Saved_Models/VGG-19_inputSize_256_09.05.2023_01..14/VGG-19_inputSize_256_09.05.2023_01..14_trained_on_87479_Data.h5', sample_image, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0643b62c",
   "metadata": {
    "id": "0643b62c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "root = \"./Models_Final\"\n",
    "directory = os.listdir(root)\n",
    "\n",
    "sample_image = get_sample_image(i_s)[0]\n",
    "plt.imshow(sample_image[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(i_s)\n",
    "\n",
    "train, val, test = get_data(i_s, batch_size, rotation_range, width_shift_range, height_shift_range, shear_range,\n",
    "                            zoom_range, horizontal_flip, fill_mode)\n",
    "\n",
    "for dir in directory:\n",
    "    path_temp = os.path.join(root, dir)\n",
    "    if(os.path.isdir(path_temp)):\n",
    "        path_dir = os.listdir(path_temp)\n",
    "        for entry in path_dir:\n",
    "            path = os.path.join(path_temp, entry)\n",
    "            if(path.endswith(\".h5\")):\n",
    "                print(f'Working on -- {path}')\n",
    "\n",
    "\n",
    "                model = tf.keras.models.load_model(path)\n",
    "\n",
    "                model_summary_path = os.path.join(path_temp, f\"{entry}_summary.jpeg\")\n",
    "                print(model_summary_path)\n",
    "                tf.keras.utils.plot_model(model, to_file=model_summary_path, show_shapes=True)\n",
    "\n",
    "                # model.summary()\n",
    "\n",
    "                # confusion_matrix(path, test)\n",
    "                print(f\".... END .... {entry}\")\n",
    "\n",
    "            extract_hidden_layer_data(path, sample_image, 16)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "66ba5e43",
    "0643b62c"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "tf_py3.8",
   "language": "python",
   "name": "tf_py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
